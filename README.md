Русский <br>
Описание проекта <br>
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Я обучил модель классифицировать комментарии на позитивные и негативные. В моем распоряжении набор данных с разметкой о токсичности правок. Я построил модель со значением метрики качества F1 не меньше 0.75.  <br>

Описание данных <br>
Столбец text в нём содержит текст комментария, а toxic — целевой признак. <br>

<br>
<br>
<br>

English <br>
Description of the project <br>
The online store "Wikishop" is launching a new service. Now users can edit and add to product descriptions, just like in wiki communities. That is, customers suggest their edits and comment on changes made by others. The store needs a tool that will find toxic comments and send them for moderation.
Train a model to classify comments as positive or negative. You have at your disposal a dataset marked for toxicity of edits.
Build a model with a quality metric F1 score of no less than 0.75. <br>

Data descriptions <br>
The 'text' column contains the comment text, and 'toxic' is the target feature. <br>

